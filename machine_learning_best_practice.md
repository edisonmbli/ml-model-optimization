# 1）问题定义
- 明确业务目标，任务类型
- 选择性能指标（结合任务类型、标签数据分布）

# 2）数据管理
- 隔离测试集，避免数据泄漏
- 可以使用sklearn的train_test_split()，对数据进行拆分
- 如果标签分布明显有偏，或根据业务背景某些字段对预测影响较大，则需要分层采样stratify

# 3）数据探索
- head()、info()、describe()、value_counts()
- df.hist()：为每个数值属性绘制直方图，视情况进一步下钻可视化
- 了解数据集的特征、标签属性：名称、类别、整数/浮点数、有界/无界数据、文本、结构化数据等
- 了解数据集的特征、标签分布：对于长尾分布，考虑log转换以缓解模型偏差
- 缺失值：若某个特征缺失率>50%，需考虑删除或作为特殊标记
- 噪声处理：根据业务排除明显的异常数据 IsolationForest
- 寻找相关性：corr()、scatter_matrix()，初步理解特征之间、特征与目标值的相关性

# 4）数据准备
## 清洗数据
    - 删除异常值：dropna()、drop()
    - 填写缺失值（例如，使用零、均值、中位数等）：SimpleImputer

## 特征选择
    - 删除没有对任务有用的信息的属性

## 特征工程
    - 离散化连续特征：
        - 分解特征：将日期拆分为“年/月/星期”，捕捉周期性规律
        - by指定字段计算统计值，关联原数据值（要注意时间穿越的坑）
        - 组合特征：如“用户单次浏览时长×点击次数”构造交互特征
        - 二值化、区间分箱量化 pd.cut()
        - 特征转换（例如log(x)、sqrt(x)、x2等）
    - 处理文本和类别属性 
        - 把空值当作一个专属的分类值，fillNA("NONE")
        - OrdinalEncoder，有序、适合树类模型
        - OneHotEncoder，适合线形模型
        - 如分类属性有大量类别：
            1) 用与类别相关的有用数值特征来替换分类输入
            2) 特征散列化 
            3) 分箱计数 
            4) embedding学习低纬向量

## 数据缩放
    - StandardScaler()、MinMaxScaler()、TransformedTargetRegressor()
    - 主要针对线形模型（树类模型不需要）
    - 优先标准化（Z-score）而非归一化，防止异常值干扰

# 5）建模与筛选
    - 使用标准参数训练不同类别（例如，线性模型、朴素贝叶斯模型、SVM、随机森林、神经网络等）的许多快速模型，作为性能基准
    - 衡量和比较它们的性能，对于每个模型，使用N折交叉验证并计算N折数据上性能指标的均值和标准差
    - 分析每种算法最重要的变量
    - 执行一轮快速的特征选择和特征工程，对前面的5个步骤再执行一两次快速迭代
    - 列出前三到五个最有前途的模型，优先选择会犯不同类型错误的模型

# 6）模型调优
## 超参数优化
    除非要探索的超参数值非常少，否则优先选择随机搜索而不是网格搜索
    - 随机搜索：高维参数的首选（更高效覆盖最优区域）
    - 网格搜索：小参数空间适用（如3x3组合）
    - 贝叶斯优化：适用于训练时间长的模型（如深度学习）
## 模型集成
  - Stacking：用基模型预测结果作为新特征输入元模型
  - 投票机制：分类任务中综合多个模型的预测概率加权平均