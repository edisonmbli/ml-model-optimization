# 1）问题定义
- 明确业务目标，任务类型
- 选择性能指标（结合任务类型、标签数据分布）

# 2）数据管理
- 隔离测试集，避免数据泄漏
- 可以使用sklearn的train_test_split()，对数据进行拆分
- 如果标签分布明显有偏，或根据业务背景某些字段对预测影响较大，则需要分层采样stratify

# 3）数据探索
1. 数据集基本情况：譬如数据有多大，每个字段各是什么类型，可以使用head()、info()、describe()、value_counts()
2. 重复值、缺失值和异常值：去除重复值，检查缺失值是否严重、缺失值是否有特殊含义，如何发现异常值
3. 特征之间是否冗余：比如身高的单位用cm和m表示就存在冗余，可以通过特征间相似性分析来找出冗余特征
4. 是否存在时间信息：当存在时间信息时，通常要进行相关性、趋势性、周期性和异常点的分析，同时还有可能涉及潜在的数据穿越问题
5. 标签分布：对于分类问题，是否存在类别分布不均衡。对于回归问题，是否存在异常值、整体分布如何，是否需要进行目标转换，譬如log转换
6. 训练集与测试集的分布：是否存在很多在测试集中存在的特征字段在训练集中没有。
7. 单变量/多变量分布，初步理解特征之间、特征与目标值的相关性，可以使用corr()、scatter_matrix()
    - 熟悉特征的分布情况，为每个数值属性绘制直方图，视情况进一步下钻可视化，可以使用df.hist()
    - 特征和标签的关系

# 4）数据准备
## 清洗数据
    - 删除异常值：dropna()、drop()
    - 填写缺失值（例如，使用零、均值、中位数等）：SimpleImputer

## 特征选择
    - 删除没有对任务有用的信息的属性

## 特征工程
    - 离散化连续特征：
        - 分解特征：将日期拆分为“年/月/星期”，捕捉周期性规律
        - by指定字段计算统计值，关联原数据值（要注意时间穿越的坑）
        - 组合特征：如“用户单次浏览时长×点击次数”构造交互特征
        - 二值化、区间分箱量化 pd.cut()
        - 特征转换（例如log(x)、sqrt(x)、x2等）
    - 处理文本和类别属性 
        - 把空值当作一个专属的分类值，fillNA("NONE")
        - OrdinalEncoder，有序、适合树类模型
        - OneHotEncoder，适合线形模型
        - 如分类属性有大量类别：
            1) 用与类别相关的有用数值特征来替换分类输入
            2) 特征散列化 
            3) 分箱计数 
            4) embedding学习低纬向量

## 数据缩放
    - StandardScaler()、MinMaxScaler()、TransformedTargetRegressor()
    - 主要针对线形模型（树类模型不需要）
    - 优先标准化（Z-score）而非归一化，防止异常值干扰

# 5）建模与筛选
    - 使用标准参数训练不同类别（例如，线性模型、朴素贝叶斯模型、SVM、随机森林、神经网络等）的许多快速模型，作为性能基准
    - 衡量和比较它们的性能，对于每个模型，使用N折交叉验证并计算N折数据上性能指标的均值和标准差
    - 分析每种算法最重要的变量
    - 执行一轮快速的特征选择和特征工程，对前面的5个步骤再执行一两次快速迭代
    - 列出前三到五个最有前途的模型，优先选择会犯不同类型错误的模型

# 6）模型调优
## 超参数优化
    除非要探索的超参数值非常少，否则优先选择随机搜索而不是网格搜索
    - 随机搜索：高维参数的首选（更高效覆盖最优区域）
    - 网格搜索：小参数空间适用（如3x3组合）
    - 贝叶斯优化：适用于训练时间长的模型（如深度学习）
## 模型集成
  - Stacking：用基模型预测结果作为新特征输入元模型
  - 投票机制：分类任务中综合多个模型的预测概率加权平均